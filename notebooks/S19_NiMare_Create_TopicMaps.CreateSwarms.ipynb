{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882bc6cd-bc01-4a50-838d-7bfdc08752dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: detected 72 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "INFO:numexpr.utils:Note: NumExpr detected 72 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "/data/SFIMJGC_HCP7T/Apps/envs/fc_introspection/lib/python3.7/site-packages/nimare/__init__.py:74: FutureWarning: Python 3.6 and 3.7 support is deprecated and will be removed in release 0.1.0 of NiMARE. Consider switching to Python 3.8, 3.9 or 3.10.\n",
      "  _python_deprecation_warnings()\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import shutil\n",
    "import os\n",
    "import nimare\n",
    "from nimare.extract import fetch_neurosynth\n",
    "from nimare.io import convert_neurosynth_to_dataset\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils.basics import PRJ_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77cfc26b-92d5-49e6-aaf6-2b396574fbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.13\n"
     ]
    }
   ],
   "source": [
    "print(nimare.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17f125-75cf-437c-9960-2f9221cfdd62",
   "metadata": {},
   "source": [
    "# 1. Folder Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a1554b-d5de-4d24-9b4c-a9c4bcf6d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = 'LDA50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac39931-a8f2-4fa2-961d-f6d43a2a0d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Resource Folder for NiMare Analyses                              : /data/SFIMJGC_Introspec/2023_fc_introspection/nimare\n",
      "++ INFO: Folder for this vocabulary                                       : /data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50\n",
      "++ INFO: Folder for meta-maps in original orientation as written by NiMare: /data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50/meta-analyses-orig\n",
      "++ INFO: Folder for meta-maps in RPI orientation (the one our data has)   : /data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50/meta-analyses-RPI\n",
      "++ ------------------------------------------------------------------------\n",
      "++ INFO: Path for NeuroSynth Dataset in NiMare format                     : /data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50/neurosynth_dataset_LDA50.pkl.gz\n",
      "++ INFO: Path for locally trained LDA model.                              : /data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50/lda_model.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "RESOURCE_NIMARE_DIR  = osp.join(PRJ_DIR,'nimare')\n",
    "VOCAB_DIR            = osp.join(RESOURCE_NIMARE_DIR,vocab)\n",
    "METAMAPS_ORIG_DIR    = osp.join(VOCAB_DIR,\"meta-analyses-orig\")  # where to save meta-analysis maps\n",
    "METAMAPS_RPI_DIR     = osp.join(VOCAB_DIR,\"meta-analyses-RPI\")  # where to save meta-analysis maps\n",
    "\n",
    "ns_dset_path         = osp.join(VOCAB_DIR, f\"neurosynth_dataset_{vocab}.pkl.gz\")\n",
    "lda_model_path       = osp.join(VOCAB_DIR, f'lda_model.pkl.gz')\n",
    "\n",
    "print('++ INFO: Resource Folder for NiMare Analyses                              : %s' % RESOURCE_NIMARE_DIR)\n",
    "print('++ INFO: Folder for this vocabulary                                       : %s' % VOCAB_DIR)\n",
    "print('++ INFO: Folder for meta-maps in original orientation as written by NiMare: %s' % METAMAPS_ORIG_DIR)\n",
    "print('++ INFO: Folder for meta-maps in RPI orientation (the one our data has)   : %s' % METAMAPS_RPI_DIR)\n",
    "print('++ ------------------------------------------------------------------------')\n",
    "print('++ INFO: Path for NeuroSynth Dataset in NiMare format                     : %s' % ns_dset_path)\n",
    "print('++ INFO: Path for locally trained LDA model.                              : %s' % lda_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af82c5d-c783-4d5d-bd65-cf5bf35ab1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Setting up all necessary folders\n",
      " + WARNING: Removing folder [/data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50]\n",
      " + INFO: Generating/Regenerating output folder [/data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50]\n",
      " + INFO: Generating/Regenerating output folder [/data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50/meta-analyses-orig]\n",
      " + INFO: Generating/Regenerating output folder [/data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50/meta-analyses-RPI]\n"
     ]
    }
   ],
   "source": [
    "# Create Empty Output Folders\n",
    "# ===========================\n",
    "print(\"++ INFO: Setting up all necessary folders\")\n",
    "for folder_path in [VOCAB_DIR, METAMAPS_ORIG_DIR, METAMAPS_RPI_DIR]:\n",
    "    if osp.exists(folder_path):\n",
    "        print(\" + WARNING: Removing folder [%s]\" % folder_path)\n",
    "        shutil.rmtree(folder_path)\n",
    "    print(\" + INFO: Generating/Regenerating output folder [%s]\" % folder_path)\n",
    "    os.mkdir(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57505d2-8478-4731-8b12-9acb39557283",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Download Neurosynth 7 database\n",
    "\n",
    "First, we need to download the Neurosynth database (version 7) for the 400 Topic Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2320c3-e777-489b-bba1-e4dbdf62a634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nimare.extract.utils:Dataset created in /data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50/neurosynth\n",
      "INFO:nimare.extract.extract:Searching for any feature files matching the following criteria: [('vocab-LDA50', 'source-abstract', 'data-neurosynth', 'version-7')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Fetching neurosynth dataset for this vocabulary...\n",
      "Downloading data-neurosynth_version-7_coordinates.tsv.gz\n",
      "Downloading data-neurosynth_version-7_metadata.tsv.gz\n",
      "Downloading data-neurosynth_version-7_vocab-LDA50_keys.tsv\n",
      "Downloading data-neurosynth_version-7_vocab-LDA50_metadata.json\n",
      "Downloading data-neurosynth_version-7_vocab-LDA50_source-abstract_type-weight_features.npz\n",
      "Downloading data-neurosynth_version-7_vocab-LDA50_vocabulary.txt\n"
     ]
    }
   ],
   "source": [
    "# Download NeuroSynth database\n",
    "print(\"++ INFO: Fetching neurosynth dataset for this vocabulary...\")\n",
    "files = fetch_neurosynth(data_dir=VOCAB_DIR, version=\"7\", overwrite=False, vocab=vocab, source=\"abstract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc08eb-1e18-48f8-b16b-fbb0d4cb4ad2",
   "metadata": {},
   "source": [
    "# 3. Convert Neurosynth Database to NiMare Dataset\n",
    "\n",
    "Next, we need to convert it into a format NiMare can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd51ce49-1246-48a8-a56e-5dee0564ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:nimare.utils:Not applying transforms to coordinates in unrecognized space 'UNKNOWN'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 50s, sys: 20.6 ms, total: 2min 50s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Convert to NiMare Dataset\n",
    "neurosynth_db = files[0]\n",
    "neurosynth_dset = convert_neurosynth_to_dataset(\n",
    "        coordinates_file=neurosynth_db['coordinates'],\n",
    "        metadata_file=neurosynth_db['metadata'],\n",
    "        annotations_files=neurosynth_db['features'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea51314-dc99-4260-94ac-263c1fc501e2",
   "metadata": {},
   "source": [
    "To avoid having to do these two steps continously, we will save the NiMare version of the NeuroSynth Database to disk. If we need it again, we just have to load this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d70ad248-afad-4fa2-9633-164fee910624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Saving NeuroSynth Dataset to disk: /data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50/neurosynth_dataset_LDA50.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset as a pickle file to the Resources directory\n",
    "print (\"++ INFO: Saving NeuroSynth Dataset to disk: %s\" % ns_dset_path)\n",
    "neurosynth_dset.save(ns_dset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3999c05-c6fa-4377-a6d7-9743c6004614",
   "metadata": {},
   "source": [
    "As a sanity check, we print the labels for the first 10 topics and count how many topics in total are in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39b30658-8e89-41e5-b140-df26d48408bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: First few topics      : ['LDA50_abstract_weight__0_network_state_resting', 'LDA50_abstract_weight__1_anxiety_trait_personality', 'LDA50_abstract_weight__2_cerebellar_cerebellum_basal', 'LDA50_abstract_weight__3_cortex_anterior_cingulate', 'LDA50_abstract_weight__4_stimulus_time_repetition', 'LDA50_abstract_weight__5_gyrus_frontal_inferior', 'LDA50_abstract_weight__6_auditory_speech_temporal', 'LDA50_abstract_weight__7_reward_feedback_striatum', 'LDA50_abstract_weight__8_mpfc_social_medial', 'LDA50_abstract_weight__9_memory_working_wm']\n",
      "++ INFO: Total number of topics: 50\n"
     ]
    }
   ],
   "source": [
    "# Extract Topic Names\n",
    "topics_ORIG = neurosynth_dset.get_labels()\n",
    "print('++ INFO: First few topics      : %s' % str(topics_ORIG[0:10]))\n",
    "print('++ INFO: Total number of topics: %d' % len(topics_ORIG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7f91c-ccc6-41b1-9f98-f259fa6f7dc3",
   "metadata": {},
   "source": [
    "# 4. Train LDA Model\n",
    "\n",
    "The topic model downloaded from NeuroSynth does not include the weigths associated with how each term relates to the topic. If we want these (which can be quite useful for generating wordclouds), then we would have to train our own Latent Dirichlet allocation (LDA) topic model using NiMare.\n",
    "\n",
    "This is a very computing and memory intensive process. I was able to run it using spersist nodes with 100GB of memory and setting ```NUMEXPR_MAX_THREADS=24```. For the 50 topic model it takes several hours, for the 400 topic model it takes a few days.\n",
    "\n",
    "Here is what to do to run the models\n",
    "\n",
    "```bash\n",
    "# Once you are on a tmux/no machine terminal in an spersist node with the suggested configuration, do the following:\n",
    "\n",
    "# Enter the notebook directory\n",
    "cd /data/SFIMJGC_Introspec/2023_fc_introspection/code/fc_introspection/notebooks/\n",
    "# Set NUMEXPR_MAX_THREADS to use 24 cpus\n",
    "export NUMEXPR_MAX_THREADS=24\n",
    "# Active the correct conda environment\n",
    "source /data/SFIMJGC_HCP7T/Apps/miniconda38/etc/profile.d/conda.sh && conda activate fc_introspection\n",
    "# Run the LDA model for the 50 topics\n",
    "python ./S18_NiMare_Compute_LDA50_Models.py\n",
    "# Run the LDA model for the 400 topics\n",
    "python ./S18_NiMare_Compute_LDA400_Models.py\n",
    "```\n",
    "\n",
    "By then end, you should have two new files:\n",
    "\n",
    "* ```/data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA50/lda_model_LDA50.pkl.gz```\n",
    "* ```/data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA400/lda_model_LDA400.pkl.gz```\n",
    "\n",
    "Execution time for LDA50\n",
    "\n",
    "```\n",
    "real 341m48.019s\n",
    "user 1061m37.913s\n",
    "sys 26m45.867s\n",
    "```\n",
    "\n",
    "Execution time for LDA400\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d90cc-d0b9-465d-a630-b33e4250c059",
   "metadata": {},
   "source": [
    "## 4.1. Add new topic definitions to the NeuroSynth Database object\n",
    "\n",
    "Next, we will add the new topic models to the NeuroSynth dataset. What this means is that we will have a second version of the NeuroSynth Database object that contains not only the original topics (those available in the Neurosynth website) but also a novel version of the topics generated locally by running NiMare implementation of the LDA algorithm. \n",
    "\n",
    "Later in the code, we will be able to work with one or the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7447f0f7-5b47-4fd2-af5e-60f9f1f7e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_path = osp.join(VOCAB_DIR,f'lda_model_{vocab}.pkl.gz')\n",
    "with open(lda_model_path,'rb') as f:\n",
    "    model_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "534d4780-384b-4e65-a3af-5f6e4a795fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurosynth_EXTRA_dset = model_results['new_dset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c129fd51-bd60-4196-b502-4b5538620543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 800\n"
     ]
    }
   ],
   "source": [
    "topics       = neurosynth_dset.get_labels()\n",
    "topics_EXTRA = neurosynth_EXTRA_dset.get_labels()\n",
    "print(len(topics), len(topics_EXTRA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c414148a-ce10-480d-969d-be9d7035582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + Saving dataset to /data/SFIMJGC_Introspec/2023_fc_introspection/nimare/LDA400/neurosynth_dataset_LDA400_EXTRA.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset as a pickle file to the Resources directory\n",
    "ns_dset_EXTRA_path         = os.path.join(VOCAB_DIR, f\"neurosynth_dataset_{vocab}_EXTRA.pkl.gz\")\n",
    "print (\" + Saving dataset to %s\" % ns_dset_EXTRA_path)\n",
    "neurosynth_EXTRA_dset.save(ns_dset_EXTRA_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ef69e-1a41-4bb0-bddb-f53208d4301e",
   "metadata": {},
   "source": [
    "# 5. Generate Topic Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef04efd-7433-4791-90cc-8b35048394ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Project Dir:                  /data/SFIMJGC_Introspec/2023_fc_introspection\n",
      "++ INFO: Bash Scripts Dir:             /data/SFIMJGC_Introspec/2023_fc_introspection/code/fc_introspection/bash\n",
      "++ INFO: Data Dir:                     /data/SFIMJGC_Introspec/pdn\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import os\n",
    "from datetime import datetime\n",
    "import getpass\n",
    "import subprocess\n",
    "\n",
    "from utils.basics import get_sbj_scan_list\n",
    "\n",
    "from utils.basics import PRJ_DIR, DATA_DIR, SCRIPTS_DIR #NOTEBOOKS_DIR, RESOURCES_DINFO_DIR, PREPROCESSING_NOTES_DIR, \n",
    "print('++ INFO: Project Dir:                  %s' % PRJ_DIR) \n",
    "#print('++ INFO: Notebooks Dir:                %s' % NOTEBOOKS_DIR) \n",
    "print('++ INFO: Bash Scripts Dir:             %s' % SCRIPTS_DIR)\n",
    "#print('++ INFO: Resources (Dataset Info) Dir: %s' % RESOURCES_DINFO_DIR)\n",
    "#print('++ INFO: Pre-processing Notes Dir:     %s' % PREPROCESSING_NOTES_DIR)\n",
    "print('++ INFO: Data Dir:                     %s' % DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a586c7c-4f35-49e8-83e5-4d7a1458bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: user working now --> javiergc\n"
     ]
    }
   ],
   "source": [
    "username = getpass.getuser()\n",
    "print('++ INFO: user working now --> %s' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc3b16de-9e88-40fa-8c98-3eae702653b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: swarm_path = /data/SFIMJGC_Introspec/2023_fc_introspection/SwarmFiles.javiergc/S19_NiMareTopics_LDA400.SWARM.sh\n",
      "++ INFO: logs dir   = /data/SFIMJGC_Introspec/2023_fc_introspection/Logs.javiergc/S19_NiMareTopics_LDA400.logs\n"
     ]
    }
   ],
   "source": [
    "#user specific folders\n",
    "#=====================\n",
    "swarm_folder   = osp.join(PRJ_DIR,'SwarmFiles.{username}'.format(username=username))\n",
    "logs_folder    = osp.join(PRJ_DIR,'Logs.{username}'.format(username=username))\n",
    "\n",
    "swarm_path     = osp.join(swarm_folder,f'S19_NiMareTopics_{vocab}.SWARM.sh')\n",
    "logdir_path    = osp.join(logs_folder, f'S19_NiMareTopics_{vocab}.logs')\n",
    "print('++ INFO: swarm_path = %s' % swarm_path)\n",
    "print('++ INFO: logs dir   = %s' % logdir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01e8d0bc-a3eb-452b-8d0f-5129cdc5d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user specific folders if needed\n",
    "# ======================================\n",
    "if not osp.exists(swarm_folder):\n",
    "    os.makedirs(swarm_folder)\n",
    "    print('++ INFO: New folder for swarm files created [%s]' % swarm_folder)\n",
    "if not osp.exists(logdir_path):\n",
    "    os.makedirs(logdir_path)\n",
    "    print('++ INFO: New folder for log files created [%s]' % logdir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01a31d98-0408-4e10-b002-1e6962d01d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file\n",
    "swarm_file = open(swarm_path, \"w\")\n",
    "# Log the date and time when the SWARM file is created\n",
    "swarm_file.write('#Create Time: %s' % datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "swarm_file.write('\\n')\n",
    "# Insert comment line with SWARM command\n",
    "swarm_file.write('#swarm -f {swarm_path} -g 32 -t 8 --partition quick,norm -b 5 --time 00:48:00 --logdir {logdir_path}'.format(swarm_path=swarm_path,logdir_path=logdir_path))\n",
    "swarm_file.write('\\n')\n",
    "\n",
    "# Insert one line per subject\n",
    "for topic in topics_EXTRA:\n",
    "    topic = topic.replace(' ','-')\n",
    "    swarm_file.write(f\"export VOCAB={vocab} TOPIC={topic}; sh {SCRIPTS_DIR}/S19_NiMare_Create_TopicMaps.sh\")\n",
    "    swarm_file.write('\\n')\n",
    "swarm_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c400803-f647-4068-a19a-99b3fafc8fd9",
   "metadata": {},
   "source": [
    "# 5. Flip them to RPI\n",
    "\n",
    "> Need code to generate the master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15ac04e7-1dab-409e-a5c0-3063b9e17944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to script that will generate the corrected version of the meta-analytic maps\n",
    "nimare_flip_metamaps_script_path = osp.join(SCRIPTS_DIR,'STEP19_NiMare_Flip_TopicMaps.{vocab}.sh'.format(vocab=vocab))\n",
    "\n",
    "# Path to fMRI Dataset to be used as reference when resampling. We pick the final data in MNI space from one random subject. All other subjects should be in the same space/grid\n",
    "master_path = '/data/SFIMJGC_Introspec/2023_fc_introspection/nimare/NiMare_Decoding_Mask_GMribbon_2023.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6e7eb95-d871-437f-8852-158bb76642fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "nimare_metamaps_orig        = sorted(glob(os.path.join(METAMAPS_ORIG_DIR, f\"{vocab}_*z_desc-specificity.nii.gz\")))\n",
    "print(len(nimare_metamaps_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb28125f-0eaa-479e-a734-84ed01947141",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimare_flip_metamaps_script = open(nimare_flip_metamaps_script_path, \"w\")\n",
    "nimare_flip_metamaps_script.write('# Script to create flipped version of NiMare outputs\\n')\n",
    "nimare_flip_metamaps_script.write('module load afni\\n')\n",
    "nimare_flip_metamaps_script.write('\\n')\n",
    "nimare_flip_metamaps_script.write('set -e\\n')\n",
    "nimare_flip_metamaps_script.write('\\n')\n",
    "nimare_flip_metamaps_script.write('# Create output folder (if needed)\\n')\n",
    "nimare_flip_metamaps_script.write('if [ ! -d {out_folder} ]; then mkdir {out_folder}; fi\\n\\n'.format(out_folder=METAMAPS_RPI_DIR))\n",
    "for orig_path in nimare_metamaps_orig:\n",
    "    orig_file = osp.basename(orig_path)\n",
    "    #orig_file = orig_file.replace(' ','\\ ')\n",
    "    new_path  = osp.join(METAMAPS_RPI_DIR,orig_file)\n",
    "    #new_path  = new_path.replace(' ','-')\n",
    "    nimare_flip_metamaps_script.write('3dLRflip -LR -overwrite -prefix \"{out_file}\" \"{in_file}\"\\n'.format(in_file=orig_path, out_file=new_path))\n",
    "    nimare_flip_metamaps_script.write('3drefit -orient RPI -space MNI \"{in_file}\"\\n'.format(in_file=new_path))\n",
    "    nimare_flip_metamaps_script.write('3dresample -overwrite -master {master_path} -input \"{in_file}\" -prefix \"{out_file}\"\\n\\n'.format(master_path = master_path,\n",
    "                                                                                                                               in_file = new_path,\n",
    "                                                                                                                               out_file = new_path))\n",
    "nimare_flip_metamaps_script.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "634c7715-6196-4ef7-9e82-6dcd25aa6322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/SFIMJGC_Introspec/2023_fc_introspection/code/fc_introspection/bash/STEP19_NiMare_Flip_TopicMaps.LDA400.sh'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nimare_flip_metamaps_script_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb93b0-c9e8-45b5-b071-ece65f24a5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "FC Introspection (Jan 2023)",
   "language": "python",
   "name": "fc_introspection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

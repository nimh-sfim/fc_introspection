{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbb2de9-520d-4355-8380-03f062593c60",
   "metadata": {},
   "source": [
    "# Description - Create Swarm File to run transformation to MNI pipeline on the preprocessed data\n",
    "\n",
    "This script creates the SWARM file to run the pipeline that will transform the data to MNI space, which is necessary for the following step of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71384c48-817a-421c-bdd1-65447c0ed5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Project Dir:                  /data/SFIMJGC_Introspec/2023_fc_introspection\n",
      "++ INFO: Bash Scripts Dir:             /data/SFIMJGC_Introspec/2023_fc_introspection/code/fc_introspection/bash\n",
      "++ INFO: Data Dir:                     /data/SFIMJGC_Introspec/pdn\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import os\n",
    "from datetime import datetime\n",
    "import getpass\n",
    "import subprocess\n",
    "\n",
    "from utils.basics import get_sbj_scan_list\n",
    "\n",
    "from utils.basics import PRJ_DIR, DATA_DIR, SCRIPTS_DIR #NOTEBOOKS_DIR, RESOURCES_DINFO_DIR, PREPROCESSING_NOTES_DIR, \n",
    "print('++ INFO: Project Dir:                  %s' % PRJ_DIR) \n",
    "#print('++ INFO: Notebooks Dir:                %s' % NOTEBOOKS_DIR) \n",
    "print('++ INFO: Bash Scripts Dir:             %s' % SCRIPTS_DIR)\n",
    "#print('++ INFO: Resources (Dataset Info) Dir: %s' % RESOURCES_DINFO_DIR)\n",
    "#print('++ INFO: Pre-processing Notes Dir:     %s' % PREPROCESSING_NOTES_DIR)\n",
    "print('++ INFO: Data Dir:                     %s' % DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d45197b-74cf-440e-ae5d-e83e5351f194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: user working now --> javiergc\n"
     ]
    }
   ],
   "source": [
    "username = getpass.getuser()\n",
    "print('++ INFO: user working now --> %s' % username)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a9eb4f-7971-48f0-81cf-31a868ca44c5",
   "metadata": {},
   "source": [
    "# 1. Load list of scans that completed struct and func pre-processing and have low motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af087272-d555-41eb-b93c-1f83972d2aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ [post_motion] Number of subjects: 133 subjects\n",
      "++ [post_motion] Number of scans:    471 scans\n"
     ]
    }
   ],
   "source": [
    "sbj_list, scan_list, SNYCQ_data = get_sbj_scan_list('post_motion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3611cf-a404-41a7-84ef-268c88b2a9d0",
   "metadata": {},
   "source": [
    "# 2. Create Output Folder for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a8119e-d4c0-4839-a616-a6f203e94383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sbj in sbj_list:\n",
    "    output_path = osp.join(DATA_DIR,'PrcsData',sbj,'preprocessed','func','pb05_mni')\n",
    "    if not osp.exists(output_path):\n",
    "        os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea3499-8f39-4506-82dc-ca7ce392df10",
   "metadata": {},
   "source": [
    "***\n",
    "# 3. Create SWARM file\n",
    "\n",
    "This will create a swarm file with one line call per subject. The inputs to that bash script are:\n",
    "\n",
    "* SBJ = subject ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617e8084-a37b-4850-a310-3737a74e8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user specific folders\n",
    "#=====================\n",
    "swarm_folder   = osp.join(PRJ_DIR,'SwarmFiles.{username}'.format(username=username))\n",
    "logs_folder    = osp.join(PRJ_DIR,'Logs.{username}'.format(username=username))\n",
    "\n",
    "swarm_path     = osp.join(swarm_folder,'S04_TransformToMNI.pass01.SWARM.sh')\n",
    "logdir_path    = osp.join(logs_folder, 'S04_TransformToMNI.pass01.logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65daf774-6b15-43b4-8879-24030b23c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user specific folders if needed\n",
    "# ======================================\n",
    "if not osp.exists(swarm_folder):\n",
    "    os.makedirs(swarm_folder)\n",
    "    print('++ INFO: New folder for swarm files created [%s]' % swarm_folder)\n",
    "if not osp.exists(logdir_path):\n",
    "    os.makedirs(logdir_path)\n",
    "    print('++ INFO: New folder for log files created [%s]' % logdir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70f870fa-3d35-426e-ad12-2cec68ecac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file\n",
    "swarm_file = open(swarm_path, \"w\")\n",
    "# Log the date and time when the SWARM file is created\n",
    "swarm_file.write('#Create Time: %s' % datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "swarm_file.write('\\n')\n",
    "# Insert comment line with SWARM command\n",
    "swarm_file.write('#swarm -f {swarm_path} -g 32 -t 32 --partition quick,norm --logdir {logdir_path}'.format(swarm_path=swarm_path,logdir_path=logdir_path))\n",
    "swarm_file.write('\\n')\n",
    "\n",
    "# Insert one line per subject\n",
    "for sbj,run in scan_list:\n",
    "    run = run[-2:] + \"_\" + run[12:18]\n",
    "    swarm_file.write(\"export SBJ={sbj} RUN={RUN}; sh {scripts_folder}/S04_TransformToMNI.pass01.sh\".format(sbj=sbj, RUN=run, scripts_folder = SCRIPTS_DIR))\n",
    "    swarm_file.write('\\n')\n",
    "swarm_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0b933-c2ad-4532-8316-ac6dcf938138",
   "metadata": {},
   "source": [
    "By the end of these jobs, we will have two new files in ```DATA_DIR/PrcsData/<SBJ>/preprocessed/func/```\n",
    "\n",
    "* ```pb05_mni/<SCAN_ID>/rest2mni.nii.gz``` MNI Version of the motion corrected resting-state scan.\n",
    "* ```pb05_mni/<SCAN_ID>/rest_mean_2mni.nii.gz``` MNI Version of the temporal mean of the file above. \n",
    "\n",
    "Becuase those files are very large (~2GB per scan), we decided to trim the corners of the files that contain no brain tissue. This required the following additional steps:\n",
    "\n",
    "1. Create a common grid that would accomodate all scans\n",
    "\n",
    "2. Cut the scans to be on that grid.\n",
    "\n",
    "The following cells help us accomplish these two tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fecd4c9-d3cd-42bb-bf5d-4f999f987c03",
   "metadata": {},
   "source": [
    "# 4. Compute common small size grid (only brain tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c85feb9-ce3a-4646-8514-c1276b16015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loading AFNI current-openmp  ... \n",
      "AFNI/current-openmp last updated  2023-01-22\n",
      "\n",
      "++ 3dMean: AFNI version=AFNI_23.0.01 (Jan 18 2023) [64-bit]\n",
      "++ 3dAutomask: AFNI version=AFNI_23.0.01 (Jan 18 2023) [64-bit]\n",
      "++ Authored by: Emperor Zhark\n",
      "++ Loading dataset all_mean.nii.gz\n",
      "++ Forming automask\n",
      " + Fixed clip level = 268.126709\n",
      " + Used gradual clip level = 216.908188 .. 341.057709\n",
      " + Number voxels above clip level = 220587\n",
      " + Clustering voxels ...\n",
      " + Largest cluster has 219159 voxels\n",
      " + Clustering voxels ...\n",
      " + Largest cluster has 218471 voxels\n",
      " + Filled   534 voxels in small holes; now have 219005 voxels\n",
      " + Filled  2154 voxels in large holes; now have 221159 voxels\n",
      " + Clustering voxels ...\n",
      " + Largest cluster has 221156 voxels\n",
      " + Clustering non-brain voxels ...\n",
      " + Clustering voxels ...\n",
      " + Largest cluster has 681473 voxels\n",
      " + Mask now has 221156 voxels\n",
      "++ 221156 voxels in the mask [out of 902629: 24.50%]\n",
      "++ first   8 x-planes are zero [from R]\n",
      "++ last   11 x-planes are zero [from L]\n",
      "++ first   9 y-planes are zero [from P]\n",
      "++ last    7 y-planes are zero [from A]\n",
      "++ first   0 z-planes are zero [from I]\n",
      "++ last   13 z-planes are zero [from S]\n",
      "++ Output dataset ./all_mean.SS.nii.gz\n",
      "++ CPU time = 0.000000 sec\n",
      "++ no -frac option: defaulting to -union\n",
      "++ processing 1 input dataset(s), NN=2...\n",
      "++ padding all datasets by 1 (for dilations)\n",
      "++ frac 0 over 1 volumes gives min count 0\n",
      "++ voxel limits: 0 clipped, 248831 survived, 653798 were zero\n",
      "++ writing result all_mean.mask.nii.gz...\n",
      "++ Output dataset ./all_mean.mask.nii.gz\n",
      "++ no -frac option: defaulting to -union\n",
      "++ processing 1 input dataset(s), NN=2...\n",
      "++ padding all datasets by 0 (for dilations)\n",
      "++ frac 0 over 1 volumes gives min count 0\n",
      "++ voxel limits: 0 clipped, 248831 survived, 653798 were zero\n",
      "++ filled 5 holes (406 voxels)\n",
      "++ writing result all_mean.mask.nii.gz...\n",
      "++ Output dataset ./all_mean.mask.nii.gz\n",
      "++ 3dAutobox: AFNI version=AFNI_23.0.01 (Jan 18 2023) [64-bit]\n",
      "++ Auto bbox: x=7..80  y=8..102  z=0..78\n",
      "++ 3dAutobox: output dataset = ./all_mean.box.nii.gz\n",
      "++ 3drefit: AFNI version=AFNI_23.0.01 (Jan 18 2023) [64-bit]\n",
      "++ Authored by: RW Cox\n",
      "++ Processing AFNI dataset all_mean.box.nii.gz\n",
      " + loading and re-writing dataset all_mean.box.nii.gz (/gpfs/gsfs11/users/SFIMJGC_Introspec/pdn/PrcsData/ALL_SCANS/all_mean.box.nii.gz in NIFTI storage)\n",
      "++ Processing AFNI dataset all_mean.mask.nii.gz\n",
      " + loading and re-writing dataset all_mean.mask.nii.gz (/gpfs/gsfs11/users/SFIMJGC_Introspec/pdn/PrcsData/ALL_SCANS/all_mean.mask.nii.gz in NIFTI storage)\n",
      "++ Processing AFNI dataset all_mean.nii.gz\n",
      " + loading and re-writing dataset all_mean.nii.gz (/gpfs/gsfs11/users/SFIMJGC_Introspec/pdn/PrcsData/ALL_SCANS/all_mean.nii.gz in NIFTI storage)\n",
      "++ Processing AFNI dataset all_mean.SS.nii.gz\n",
      " + loading and re-writing dataset all_mean.SS.nii.gz (/gpfs/gsfs11/users/SFIMJGC_Introspec/pdn/PrcsData/ALL_SCANS/all_mean.SS.nii.gz in NIFTI storage)\n",
      "++ 3drefit processed 4 datasets\n",
      "++ 3dZeropad: AFNI version=AFNI_23.0.01 (Jan 18 2023) [64-bit]\n",
      "++ 3dZeropad -master => -I 0 -S -12 -A -6 -P -8 -R -7 -L -10\n",
      "++ output dataset: ./all_mean.boxed.nii.gz\n",
      "++ 3dZeropad: AFNI version=AFNI_23.0.01 (Jan 18 2023) [64-bit]\n",
      "++ 3dZeropad -master => -I 0 -S -12 -A -6 -P -8 -R -7 -L -10\n",
      "++ output dataset: ./all_mean.SS.boxed.nii.gz\n",
      "++ 3dZeropad: AFNI version=AFNI_23.0.01 (Jan 18 2023) [64-bit]\n",
      "++ 3dZeropad -master => -I 0 -S -12 -A -6 -P -8 -R -7 -L -10\n",
      "++ output dataset: ./all_mean.mask.boxed.nii.gz\n",
      "++ INFO: Script finished correctly\n"
     ]
    }
   ],
   "source": [
    "command = \"\"\"module load afni; \\\n",
    "             sh {PRJ_DIR}/code/fc_introspection/bash/S04_TransformToMNI.pass02.sh\"\"\".format(PRJ_DIR=PRJ_DIR)\n",
    "output  = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT)\n",
    "print(output.strip().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2d530-7c7e-4888-a560-7c6bc41582dc",
   "metadata": {},
   "source": [
    ">**NOTE**: Automask sometimes leaves a bit of skull on the left side of the brain. We will manually correct this error on all_mean.mask.boxed.nii.gz using AFNI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d8adc5-2abc-4201-9194-cc0bb4dd6be2",
   "metadata": {},
   "source": [
    "# 5. Enforce new grid on files generated during step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42fe3e64-1253-40ea-bfa1-391589ce020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user specific folders\n",
    "#=====================\n",
    "swarm_path     = osp.join(swarm_folder,'S04_TransformToMNI.pass03.SWARM.sh')\n",
    "logdir_path    = osp.join(logs_folder, 'S04_TransformToMNI.pass03.logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc412222-a91b-499e-9563-d620419cac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: New folder for log files created [/data/SFIMJGC_Introspec/2023_fc_introspection/Logs.javiergc/S04_TransformToMNI.pass03.logs]\n"
     ]
    }
   ],
   "source": [
    "# create user specific folders if needed\n",
    "# ======================================\n",
    "if not osp.exists(swarm_folder):\n",
    "    os.makedirs(swarm_folder)\n",
    "    print('++ INFO: New folder for swarm files created [%s]' % swarm_folder)\n",
    "if not osp.exists(logdir_path):\n",
    "    os.makedirs(logdir_path)\n",
    "    print('++ INFO: New folder for log files created [%s]' % logdir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04063d15-f65f-4ca7-b74a-29a527bf0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file\n",
    "swarm_file = open(swarm_path, \"w\")\n",
    "# Log the date and time when the SWARM file is created\n",
    "swarm_file.write('#Create Time: %s' % datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "swarm_file.write('\\n')\n",
    "# Insert comment line with SWARM command\n",
    "swarm_file.write('#swarm -f {swarm_path} -g 32 -t 32 --partition quick,norm --logdir {logdir_path}'.format(swarm_path=swarm_path,logdir_path=logdir_path))\n",
    "swarm_file.write('\\n')\n",
    "\n",
    "# Insert one line per subject\n",
    "for sbj,run in scan_list:\n",
    "    run = run[-2:] + \"_\" + run[12:18]\n",
    "    swarm_file.write(\"export SBJ={sbj} RUN={RUN}; sh {scripts_folder}/S04_TransformToMNI.pass03.sh\".format(sbj=sbj, RUN=run, scripts_folder = SCRIPTS_DIR))\n",
    "    swarm_file.write('\\n')\n",
    "swarm_file.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "FC Introspection (Jan 2023)",
   "language": "python",
   "name": "fc_introspection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

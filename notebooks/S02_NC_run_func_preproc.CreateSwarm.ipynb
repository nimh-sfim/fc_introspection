{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description - Create Swarm File to run lsd functional pre-processing pipeline on NC dataset\n",
    "\n",
    "This script creates the swarm file to run the functional pre-processing pipeline on the lsd (NC) portion of the lemon dataset. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Project Dir:                  /data/SFIMJGC_Introspec/2023_fc_introspection\n",
      "++ INFO: Notebooks Dir:                /data/SFIMJGC_Introspec/2023_fc_introspection/code/fc_introspection/notebooks\n",
      "++ INFO: Bash Scripts Dir:             /data/SFIMJGC_Introspec/2023_fc_introspection/code/fc_introspection/bash\n",
      "++ INFO: Resources (Dataset Info) Dir: /data/SFIMJGC_Introspec/2023_fc_introspection/resources/dataset_info\n",
      "++ INFO: Pre-processing Notes Dir:     /data/SFIMJGC_Introspec/2023_fc_introspection/code/fc_introspection/resources/preprocessing_notes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import os\n",
    "from datetime import datetime\n",
    "import getpass\n",
    "from utils.basics import PRJ_DIR, NOTEBOOKS_DIR, SCRIPTS_DIR, RESOURCES_DINFO_DIR, PREPROCESSING_NOTES_DIR\n",
    "print('++ INFO: Project Dir:                  %s' % PRJ_DIR) \n",
    "print('++ INFO: Notebooks Dir:                %s' % NOTEBOOKS_DIR) \n",
    "print('++ INFO: Bash Scripts Dir:             %s' % SCRIPTS_DIR)\n",
    "print('++ INFO: Resources (Dataset Info) Dir: %s' % RESOURCES_DINFO_DIR)\n",
    "print('++ INFO: Pre-processing Notes Dir:     %s' % PREPROCESSING_NOTES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: user working now --> javiergc\n"
     ]
    }
   ],
   "source": [
    "username = getpass.getuser()\n",
    "print('++ INFO: user working now --> %s' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user specific folders\n",
    "#=====================\n",
    "swarm_folder   = osp.join(PRJ_DIR,'SwarmFiles.{username}'.format(username=username))\n",
    "logs_folder    = osp.join(PRJ_DIR,'Logs.{username}'.format(username=username))\n",
    "logdir_path    = osp.join(logs_folder,'S02_NC_run_func_preproc.logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user specific folders if needed\n",
    "# ======================================\n",
    "if not osp.exists(swarm_folder):\n",
    "    os.makedirs(swarm_folder)\n",
    "    print('++ INFO: New folder for swarm files created [%s]' % swarm_folder)\n",
    "if not osp.exists(logs_folder):\n",
    "    os.makedirs(logs_folder)\n",
    "    print('++ INFO: New folder for log files created [%s]' % logs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_info_path           = osp.join(RESOURCES_DINFO_DIR,'NC_anat_info.pkl')\n",
    "bad_struct_subjects_path = osp.join(RESOURCES_DINFO_DIR,'NC_struc_fail_list.csv')\n",
    "swarm_path               = osp.join(swarm_folder,'S02_NC_run_func_preproc.SWARM.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1. Load list of subjects with at least one rest run with accompanying SNYQ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Number of subjects: 175\n"
     ]
    }
   ],
   "source": [
    "sbj_list = (pd.read_csv(osp.join(RESOURCES_DINFO_DIR,'NC_withSNYCQ_subjects.txt'), header=None)[0]).tolist()\n",
    "print(\"++ INFO: Number of subjects: %s\" % len(sbj_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2. Load list of subjects that failed structural pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Number of subjects with incomplete structural pre-processing:                          25 subjects\n",
      "++ INFO: Number of rest scans that will be removed due to incomplete structural pre-processing: 96 scans \n"
     ]
    }
   ],
   "source": [
    "bad_struct_sbj_df   = pd.read_csv(osp.join(PREPROCESSING_NOTES_DIR,'NC_struct_fail_list.csv'))\n",
    "bad_struct_sbj_list = list(bad_struct_sbj_df['Subject'].values)\n",
    "bad_struct_sbj_df.head()\n",
    "print(\"++ INFO: Number of subjects with incomplete structural pre-processing:                          %d subjects\" % len(bad_struct_sbj_list))\n",
    "print(\"++ INFO: Number of rest scans that will be removed due to incomplete structural pre-processing: %d scans \" % bad_struct_sbj_df['func_scans'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3. Don't attempt functional pre-processing on subjects that failed the structural\n",
    "\n",
    "If the structual pre-processing failed for a subject, we will not be able to complete our analysis. For that reason, we will not attempt functional pre-processing of scans from subjects with failed anatomical scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Number of subjects for which we will attempt functional pre-processing: 150\n"
     ]
    }
   ],
   "source": [
    "sbj_list = [sbj for sbj in sbj_list if sbj not in bad_struct_sbj_list]\n",
    "print('++ INFO: Number of subjects for which we will attempt functional pre-processing: %d' % len(sbj_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2. Create Log Directory for swarm jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Log folder created [/data/SFIMJGC_Introspec/2023_fc_introspection/Logs.javiergc/S02_NC_run_func_preproc.logs]\n"
     ]
    }
   ],
   "source": [
    "if not osp.exists(logdir_path):\n",
    "    os.mkdir(logdir_path)\n",
    "    print(\"++ INFO: Log folder created [%s]\" % logdir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 2. Create Swarm File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Open the file\n",
    "swarm_file = open(swarm_path, \"w\")\n",
    "# Log the date and time when the SWARM file is created\n",
    "swarm_file.write('#Create Time: %s' % datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "swarm_file.write('\\n')\n",
    "# Insert comment line with SWARM command\n",
    "swarm_file.write('#swarm -f {swarm_path} -g 32 -t 32 --time 32:00:00 --logdir {logdir_path}'.format(swarm_path=swarm_path, logdir_path=logdir_path))\n",
    "swarm_file.write('\\n')\n",
    "\n",
    "# Insert one line per subject\n",
    "for sbj in sbj_list:\n",
    "    swarm_file.write(\"export SBJ={sbj}; sh {scripts_folder}/S02_NC_run_func_preproc.sh\".format(sbj=sbj,scripts_folder=SCRIPTS_DIR))\n",
    "    swarm_file.write('\\n')\n",
    "swarm_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ INFO: Swarm file available at: /data/SFIMJGC_Introspec/2023_fc_introspection/SwarmFiles.javiergc/S02_NC_run_func_preproc.SWARM.sh\n"
     ]
    }
   ],
   "source": [
    "print('++ INFO: Swarm file available at: %s' % swarm_path)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "FC Instrospection (Jan 2023)",
   "language": "python",
   "name": "fc_introspection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
